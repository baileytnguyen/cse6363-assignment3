{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U2HphIV3QCO"
      },
      "source": [
        "# Bailey's Deeping Learning Assignment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network 1: Basic CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create basic CNN model using Immagenette dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CnnModel(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # use cnn\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(\n",
        "            task=\"multiclass\", num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)  # No need to reshape here!\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import Imagenette\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# prepare data for cnn taking 64x64 greyscale images\n",
        "cnn_train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.Resize(64),\n",
        "        transforms.Grayscale(),  # Move this before ToTensor()\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),  # Adjust normalization for 1 channel\n",
        "    ]\n",
        ")\n",
        "\n",
        "cnn_test_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.Resize(64),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),\n",
        "    ]\n",
        ")\n",
        "cnn_train_dataset = Imagenette(\n",
        "    \"data/imagenette/train/\",\n",
        "    split=\"train\",\n",
        "    size=\"160px\",\n",
        "    download=False,\n",
        "    transform=cnn_train_transforms,\n",
        ")\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "cnn_train_set_size = int(len(cnn_train_dataset) * 0.9)\n",
        "cnn_val_set_size = len(cnn_train_dataset) - cnn_train_set_size\n",
        "\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "cnn_train_dataset, cnn_val_dataset = torch.utils.data.random_split(\n",
        "    cnn_train_dataset, [cnn_train_set_size, cnn_val_set_size], generator=seed\n",
        ")\n",
        "cnn_val_dataset.dataset.transform = cnn_test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "cnn_train_loader = torch.utils.data.DataLoader(\n",
        "    cnn_train_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "cnn_val_loader = torch.utils.data.DataLoader(\n",
        "    cnn_val_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=False,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "# Configure the test dataset\n",
        "cnn_test_dataset = Imagenette(\n",
        "    \"data/imagenette/test/\",\n",
        "    split=\"val\",\n",
        "    size=\"160px\",\n",
        "    download=False,\n",
        "    transform=cnn_test_transforms,\n",
        ")\n",
        "\n",
        "cnn_model = CnnModel()\n",
        "\n",
        "# Add EarlyStopping\n",
        "cnn_early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "\n",
        "# Configure Checkpoints\n",
        "cnn_checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | estimator | Sequential         | 2.1 M  | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "2.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.470     Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 67/67 [00:01<00:00, 39.72it/s, v_num=7]           \n"
          ]
        }
      ],
      "source": [
        "# Train cnn model\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "trainer = L.Trainer(\n",
        "    callbacks=[cnn_early_stop_callback, cnn_checkpoint_callback], max_epochs=100\n",
        ")\n",
        "trainer.fit(\n",
        "    model=cnn_model, train_dataloaders=cnn_train_loader, val_dataloaders=cnn_val_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|██████████| 31/31 [00:00<00:00, 53.56it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "      test_accuracy         0.5505732297897339\n",
            "        test_loss           1.8283294439315796\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.5505732297897339, 'test_loss': 1.8283294439315796}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "cnn_test_loader = torch.utils.data.DataLoader(\n",
        "    cnn_test_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=False,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "trainer.test(model=cnn_model, dataloaders=cnn_test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network 2: ResNet 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a ResNet model using the Imagenette dataset\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class ResNetModel(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use pretrained ResNet18 with the updated weights argument\n",
        "        self.estimator = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "        # Modify the final layer to match the number of classes\n",
        "        self.estimator.fc = nn.Linear(self.estimator.fc.in_features, num_classes)\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(\n",
        "            task=\"multiclass\", num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import Imagenette\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "# prepare data for ResNet 18 model taking 64x64 RGB images\n",
        "resnet_train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "resnet_test_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "resnet_train_dataset = Imagenette(\n",
        "    \"data/imagenette/train/\",\n",
        "    split=\"train\",\n",
        "    size=\"160px\",\n",
        "    download=False,\n",
        "    transform=resnet_train_transforms,\n",
        ")\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "resnet_train_set_size = int(len(resnet_train_dataset) * 0.9)\n",
        "resnet_val_set_size = len(resnet_train_dataset) - resnet_train_set_size\n",
        "\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "resnet_train_dataset, resnet_val_dataset = torch.utils.data.random_split(\n",
        "    resnet_train_dataset, [resnet_train_set_size, resnet_val_set_size], generator=seed\n",
        ")\n",
        "resnet_val_dataset.dataset.transform = resnet_test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "resnet_train_loader = torch.utils.data.DataLoader(\n",
        "    resnet_train_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "resnet_val_loader = torch.utils.data.DataLoader(\n",
        "    resnet_val_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=False,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "# Configure the test dataset\n",
        "resnet_test_dataset = Imagenette(\n",
        "    \"data/imagenette/test/\",\n",
        "    split=\"val\",\n",
        "    size=\"160px\",\n",
        "    download=False,\n",
        "    transform=resnet_test_transforms,\n",
        ")\n",
        "\n",
        "resnet_model = ResNetModel()\n",
        "\n",
        "# Add EarlyStopping\n",
        "resnet_early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "\n",
        "# Configure Checkpoints\n",
        "resnet_checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | estimator | ResNet             | 11.2 M | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.727    Total estimated model params size (MB)\n",
            "69        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 67/67 [00:02<00:00, 27.76it/s, v_num=10]          \n"
          ]
        }
      ],
      "source": [
        "# Train ResNet model\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    callbacks=[resnet_early_stop_callback, resnet_checkpoint_callback], max_epochs=100\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=resnet_model,\n",
        "    train_dataloaders=resnet_train_loader,\n",
        "    val_dataloaders=resnet_val_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|██████████| 31/31 [00:00<00:00, 44.80it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "      test_accuracy         0.7839490175247192\n",
            "        test_loss           0.9097476005554199\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.7839490175247192, 'test_loss': 0.9097476005554199}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "restnet_test_loader = torch.utils.data.DataLoader(\n",
        "    resnet_test_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=False,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "trainer.test(model=resnet_model, dataloaders=restnet_test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CnnModelWithDropout(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # use cnn with dropout\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),  # Add dropout layer\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),  # Add dropout layer\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Add dropout layer\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(\n",
        "            task=\"multiclass\", num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)  # No need to reshape here!\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare data for cnn with dropout taking 64x64 greyscale images\n",
        "cnn_dropout_train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.Resize(64),\n",
        "        transforms.Grayscale(),  # Move this before ToTensor()\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),  # Adjust normalization for 1 channel\n",
        "    ]\n",
        ")\n",
        "\n",
        "cnn_dropout_test_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.Resize(64),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),\n",
        "    ]\n",
        ")\n",
        "cnn_dropout_train_dataset = Imagenette(\n",
        "    \"data/imagenette/train/\",\n",
        "    split=\"train\",\n",
        "    size=\"160px\",\n",
        "    download=False,\n",
        "    transform=cnn_dropout_train_transforms,\n",
        ")\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "cnn_dropout_train_set_size = int(len(cnn_dropout_train_dataset) * 0.9)\n",
        "cnn_dropout_val_set_size = len(cnn_dropout_train_dataset) - cnn_dropout_train_set_size\n",
        "\n",
        "cnn_dropout_train_dataset, cnn_dropout_val_dataset = torch.utils.data.random_split(\n",
        "    cnn_dropout_train_dataset,\n",
        "    [cnn_dropout_train_set_size, cnn_dropout_val_set_size],\n",
        "    generator=seed,\n",
        ")\n",
        "cnn_dropout_val_dataset.dataset.transform = cnn_dropout_test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "cnn_dropout_train_loader = torch.utils.data.DataLoader(\n",
        "    cnn_dropout_train_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "cnn_dropout_val_loader = torch.utils.data.DataLoader(\n",
        "    cnn_dropout_val_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=False,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "# Configure the test dataset\n",
        "cnn_dropout_test_dataset = Imagenette(\n",
        "    \"data/imagenette/test/\",\n",
        "    split=\"val\",\n",
        "    size=\"160px\",\n",
        "    download=False,\n",
        "    transform=cnn_dropout_test_transforms,\n",
        ")\n",
        "\n",
        "cnn_dropout_model = CnnModelWithDropout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory c:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\lightning_logs\\version_7\\checkpoints exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | estimator | Sequential         | 2.1 M  | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "2.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.470     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 67/67 [00:01<00:00, 39.92it/s, v_num=9]           \n"
          ]
        }
      ],
      "source": [
        "# Train cnn model with dropout\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    callbacks=[cnn_early_stop_callback, cnn_checkpoint_callback], max_epochs=100\n",
        ")\n",
        "\n",
        "trainer.fit(\n",
        "    model=cnn_dropout_model,\n",
        "    train_dataloaders=cnn_dropout_train_loader,\n",
        "    val_dataloaders=cnn_dropout_val_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|██████████| 31/31 [00:00<00:00, 46.98it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "      test_accuracy         0.31821656227111816\n",
            "        test_loss           1.9819180965423584\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.31821656227111816, 'test_loss': 1.9819180965423584}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "cnn_dropout_test_loader = torch.utils.data.DataLoader(\n",
        "    cnn_dropout_test_dataset,\n",
        "    batch_size=128,\n",
        "    num_workers=8,\n",
        "    shuffle=False,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "trainer.test(model=cnn_dropout_model, dataloaders=cnn_dropout_test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer Learning on CIFAR10 Using Dropout CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "import lightning.pytorch as pl\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CnnModelWithDropout(pl.LightningModule):\n",
        "    def __init__(self, data_path, batch_size=128, lr=1e-3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "\n",
        "        # Load CIFAR-10 dataset\n",
        "        dataset = CIFAR10(\n",
        "            data_path,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.Resize(64),  # Match CNN input size\n",
        "                    transforms.Grayscale(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5,), (0.5,)),\n",
        "                ]\n",
        "            ),\n",
        "            download=True,\n",
        "        )\n",
        "\n",
        "        dataset_size = len(dataset)\n",
        "        train_size = int(dataset_size * 0.9)\n",
        "        val_size = dataset_size - train_size\n",
        "\n",
        "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(\n",
        "            dataset, [train_size, val_size]\n",
        "        )\n",
        "\n",
        "        # Define CNN model with dropout\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "\n",
        "        # Loss & Accuracy\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "        acc = self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_accuracy\", acc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=8,\n",
        "            persistent_workers=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=8,\n",
        "            persistent_workers=True,\n",
        "        )\n",
        "\n",
        "\n",
        "model_cnn_dropout = CnnModelWithDropout(data_path=\"./data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "You passed a `lightning.pytorch` object (ModelCheckpoint) to a `pytorch_lightning` Trainer. Please switch to a single import style.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m transfer_checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtransfer_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model_cnn_dropout)\n",
            "File \u001b[1;32mc:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:426\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate_grad_batches \u001b[38;5;241m=\u001b[39m accumulate_grad_batches\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# init callbacks\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Declare attributes to be set in _callback_connector on_trainer_init\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trainer_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_checkpointing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_root_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_model_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# init data flags\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_val_every_n_epoch: Optional[\u001b[38;5;28mint\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:80\u001b[0m, in \u001b[0;36m_CallbackConnector.on_trainer_init\u001b[1;34m(self, callbacks, enable_checkpointing, enable_progress_bar, default_root_dir, enable_model_summary, max_time)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_model_summary_callback(enable_model_summary)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mextend(_load_external_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch_lightning.callbacks_factory\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 80\u001b[0m \u001b[43m_validate_callbacks_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# push all model checkpoint callbacks to the end\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# it is important that these are the last callbacks to run\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reorder_callbacks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks)\n",
            "File \u001b[1;32mc:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:228\u001b[0m, in \u001b[0;36m_validate_callbacks_list\u001b[1;34m(callbacks)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_callbacks_list\u001b[39m(callbacks: \u001b[38;5;28mlist\u001b[39m[Callback]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m     stateful_callbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_overridden\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    229\u001b[0m     seen_callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m stateful_callbacks:\n",
            "File \u001b[1;32mc:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_helpers.py:41\u001b[0m, in \u001b[0;36mis_overridden\u001b[1;34m(method_name, instance, parent)\u001b[0m\n\u001b[0;32m     39\u001b[0m         parent \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mCallback\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m         \u001b[43m_check_mixed_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightning_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_overridden \u001b[38;5;28;01mas\u001b[39;00m _is_overridden\n",
            "File \u001b[1;32mc:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_helpers.py:96\u001b[0m, in \u001b[0;36m_check_mixed_imports\u001b[1;34m(instance)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed a `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(instance)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to a `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Trainer. Please switch to a single import style.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m )\n",
            "\u001b[1;31mTypeError\u001b[0m: You passed a `lightning.pytorch` object (ModelCheckpoint) to a `pytorch_lightning` Trainer. Please switch to a single import style."
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "transfer_checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(callbacks=[transfer_checkpoint_callback], max_epochs=10)\n",
        "trainer.fit(model_cnn_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "trainer.test(model_cnn_dropout)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
