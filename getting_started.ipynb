{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U2HphIV3QCO"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "In this assignment you will be implementing at least 2 unique models and working with both the CIFAR10 and Imagenette datasets. The cell below defines a basic model based on the examples we reviewed in class. You should use this as a starting point to implement your own models.\n",
        "\n",
        "You should have no problems running this notebook in Google Colab. If you choose to run it on your own machine, a yaml file is provided with the necessary dependencies. If you are using anaconda, you can create a new environment with the following command:\n",
        "\n",
        "```bash\n",
        "conda env create -f env.yml\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "JIH6e96Z3QCP",
        "outputId": "b391d6d2-57cd-495e-c731-f95f2e12122d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class BaselineModel(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Linear(64 * 64, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        return self.estimator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXieKV-w3QCQ"
      },
      "source": [
        "The Imagenette dataset is a smaller subset of 10 easily classified classes from Imagenet. It is available to download from `torchvision`, as shown in the cell below. There are 3 different sizes of the images available. Feel free to use whichever version you prefer. It might make a difference in the performance of your model.\n",
        "\n",
        "**Note: After downloading the Imagenette dataset, you will need to set `download=False` in the cell below to avoid errors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QNN_j8t3QCQ",
        "outputId": "107e6e6d-7a34-40e8-fdb2-1f7e47c05444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to data/imagenette/train/imagenette2-160.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99003388/99003388 [00:16<00:00, 6100889.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/imagenette/train/imagenette2-160.tgz to data/imagenette/train/\n",
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to data/imagenette/test/imagenette2-160.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99003388/99003388 [00:19<00:00, 5067238.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/imagenette/test/imagenette2-160.tgz to data/imagenette/test/\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import Imagenette\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# Prepare the dataset\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    transforms.Grayscale()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    transforms.Grayscale()\n",
        "])\n",
        "\n",
        "train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=False, transform=train_transforms)\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "train_set_size = int(len(train_dataset) * 0.9)\n",
        "val_set_size = len(train_dataset) - train_set_size\n",
        "\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_set_size, val_set_size], generator=seed)\n",
        "val_dataset.dataset.transform = test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
        "\n",
        "# Configure the test dataset\n",
        "test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=False, transform=test_transforms)\n",
        "\n",
        "model = BaselineModel()\n",
        "\n",
        "# Add EarlyStopping\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n",
        "                                    mode=\"min\",\n",
        "                                    patience=5)\n",
        "\n",
        "# Configure Checkpoints\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "77efda4c66d340c5af54b8957d8cb12d",
            "a3240dc96427474598dc85be9e0a18a0",
            "6339620d653a4a4eb8227fecc351707c",
            "0ae5de5d8cc44de8a46257f2c5c00f86"
          ]
        },
        "id": "JinwQAQL3QCR",
        "outputId": "abfbcfff-baf7-4206-c798-2a9a0c6f1b82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name      | Type               | Params | Mode\n",
            "--------------------------------------------------------\n",
            "0 | estimator | Sequential         | 4.8 M  | eval\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | eval\n",
            "--------------------------------------------------------\n",
            "4.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.8 M     Total params\n",
            "19.148    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b6c1515c694429fbc7aa0ee88afc7a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b2db61fe1804940879a9f9e22b101f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bdbe4ea94204139b388ed1b5b9c89fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "793e682f82134b53971c42582d27c208",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42cc96a2dca042b3b1d056d71231a8fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback], max_epochs=3)\n",
        "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KGEFGZry3QCR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30057915b67a413cb7b90cfa7f36f976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3133758008480072     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.9762518405914307     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3133758008480072    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.9762518405914307    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.3133758008480072, 'test_loss': 1.9762518405914307}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, num_workers=8, shuffle=False)\n",
        "trainer.test(model=model, dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network 1: Basic CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create basic CNN model using Immagenette dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CnnModel(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # use cnn\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)  # No need to reshape here!\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# prepare data for cnn taking 64x64 greyscale images\n",
        "cnn_train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.Grayscale(),  # Move this before ToTensor()\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # Adjust normalization for 1 channel\n",
        "])\n",
        "\n",
        "cnn_test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "cnn_train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=False, transform=cnn_train_transforms)\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "cnn_train_set_size = int(len(cnn_train_dataset) * 0.9)\n",
        "cnn_val_set_size = len(cnn_train_dataset) - cnn_train_set_size\n",
        "\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "cnn_train_dataset, cnn_val_dataset = torch.utils.data.random_split(cnn_train_dataset, [cnn_train_set_size, cnn_val_set_size], generator=seed)\n",
        "cnn_val_dataset.dataset.transform = cnn_test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "cnn_train_loader = torch.utils.data.DataLoader(cnn_train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
        "cnn_val_loader = torch.utils.data.DataLoader(cnn_val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
        "\n",
        "# Configure the test dataset\n",
        "cnn_test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=False, transform=cnn_test_transforms)\n",
        "\n",
        "cnn_model = CnnModel()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | estimator | Sequential         | 2.1 M  | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "2.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.1 M     Total params\n",
            "8.470     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "708f1b5ca10d46139b4325638c3821d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "425fc7124fa34b9690605c53e9b31ef9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72a68d82697c43c7a2ac5693ad83c941",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96e69fbfa9ab43c79cd1c9559166b75f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "509b13fa4fde449380582d30f8edf8e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "# Train cnn model\n",
        "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback], max_epochs=3)\n",
        "trainer.fit(model=cnn_model, train_dataloaders=cnn_train_loader, val_dataloaders=cnn_val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b97ff6c84b834863a63959ab18e6df63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4188534915447235     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.3453874588012695     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4188534915447235    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.3453874588012695    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.4188534915447235, 'test_loss': 2.3453874588012695}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "trainer.test(model=cnn_model, dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network 2: ResNet 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a ResNet model using the Imagenette dataset\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class ResNetModel(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use pretrained ResNet18\n",
        "        self.estimator = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # Modify the final layer to match the number of classes\n",
        "        self.estimator.fc = nn.Linear(self.estimator.fc.in_features, num_classes)\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import Imagenette\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "# prepare data for ResNet 18 model taking 64x64 RGB images\n",
        "resnet_train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "resnet_test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "resnet_train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=False, transform=resnet_train_transforms)\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "resnet_train_set_size = int(len(resnet_train_dataset) * 0.9)\n",
        "resnet_val_set_size = len(resnet_train_dataset) - resnet_train_set_size\n",
        "\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "resnet_train_dataset, resnet_val_dataset = torch.utils.data.random_split(resnet_train_dataset, [resnet_train_set_size, resnet_val_set_size], generator=seed)\n",
        "resnet_val_dataset.dataset.transform = resnet_test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "resnet_train_loader = torch.utils.data.DataLoader(resnet_train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
        "resnet_val_loader = torch.utils.data.DataLoader(resnet_val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
        "\n",
        "# Configure the test dataset\n",
        "resnet_test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=False, transform=resnet_test_transforms)\n",
        "\n",
        "resnet_model = ResNetModel()\n",
        "\n",
        "# Add EarlyStopping\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n",
        "                                    mode=\"min\",\n",
        "                                    patience=5)\n",
        "\n",
        "# Configure Checkpoints\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | estimator | ResNet             | 11.2 M | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.727    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6fe6e98f5fc4d8f9c70e5c5ff4922d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0731f52a8954435081dac34229ff2ad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa0fd07be38745289717d35a2e5aaf8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "862bc95a40b44aa2a0fe8f28ab34732e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22b120bf7b6d4fdeae5829bd94349500",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "# Train ResNet model\n",
        "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback], max_epochs=3)\n",
        "trainer.fit(model=resnet_model, train_dataloaders=resnet_train_loader, val_dataloaders=resnet_val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_loader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model\u001b[38;5;241m=\u001b[39mresnet_model, dataloaders\u001b[38;5;241m=\u001b[39mtest_loader)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "trainer.test(model=resnet_model, dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CnnModelWithDropout(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # use cnn with dropout\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),  # Add dropout layer\n",
        "            \n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),  # Add dropout layer\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Add dropout layer\n",
        "            \n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)  # No need to reshape here!\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare data for cnn with dropout taking 64x64 greyscale images\n",
        "cnn_dropout_train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.Grayscale(),  # Move this before ToTensor()\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # Adjust normalization for 1 channel\n",
        "])\n",
        "\n",
        "cnn_dropout_test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "cnn_dropout_train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=False, transform=cnn_dropout_train_transforms)\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "cnn_dropout_train_set_size = int(len(cnn_dropout_train_dataset) * 0.9)\n",
        "cnn_dropout_val_set_size = len(cnn_dropout_train_dataset) - cnn_dropout_train_set_size\n",
        "\n",
        "cnn_dropout_train_dataset, cnn_dropout_val_dataset = torch.utils.data.random_split(cnn_dropout_train_dataset, [cnn_dropout_train_set_size, cnn_dropout_val_set_size], generator=seed)\n",
        "cnn_dropout_val_dataset.dataset.transform = cnn_dropout_test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "cnn_dropout_train_loader = torch.utils.data.DataLoader(cnn_dropout_train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
        "cnn_dropout_val_loader = torch.utils.data.DataLoader(cnn_dropout_val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
        "\n",
        "# Configure the test dataset\n",
        "cnn_dropout_test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=False, transform=cnn_dropout_test_transforms)\n",
        "\n",
        "cnn_dropout_model = CnnModelWithDropout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning on CIFAR10 Using Dropout CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class CnnModelWithDropout(pl.LightningModule):\n",
        "    def __init__(self, data_path, batch_size=128, lr=1e-3):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.data_path = data_path\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        \n",
        "        # Load CIFAR-10 dataset\n",
        "        dataset = CIFAR10(data_path, transform=transforms.Compose([\n",
        "            transforms.Resize(64),  # Match CNN input size\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,)),\n",
        "        ]), download=True)\n",
        "        \n",
        "        dataset_size = len(dataset)\n",
        "        train_size = int(dataset_size * 0.9)\n",
        "        val_size = dataset_size - train_size\n",
        "        \n",
        "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "        \n",
        "        # Define CNN model with dropout\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "            \n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 16 * 16, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            \n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "        \n",
        "        # Loss & Accuracy\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.estimator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "        \n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "        acc = self.accuracy(y_hat, y)\n",
        "        \n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_accuracy\", acc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
        "\n",
        "\n",
        "# Train CNN with dropout on CIFAR-10\n",
        "model_cnn_dropout = CnnModelWithDropout(data_path=\"./data\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
