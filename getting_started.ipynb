{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U2HphIV3QCO"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "In this assignment you will be implementing at least 2 unique models and working with both the CIFAR10 and Imagenette datasets. The cell below defines a basic model based on the examples we reviewed in class. You should use this as a starting point to implement your own models.\n",
        "\n",
        "You should have no problems running this notebook in Google Colab. If you choose to run it on your own machine, a yaml file is provided with the necessary dependencies. If you are using anaconda, you can create a new environment with the following command:\n",
        "\n",
        "```bash\n",
        "conda env create -f env.yml\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JIH6e96Z3QCP",
        "outputId": "b391d6d2-57cd-495e-c731-f95f2e12122d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lightning'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fcbe31849c88>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightning'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "class BaselineModel(L.LightningModule):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.estimator = nn.Sequential(\n",
        "            nn.Linear(64 * 64, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        return self.estimator(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"val_accuracy\", self.accuracy)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "\n",
        "        self.accuracy(y_hat, y)\n",
        "\n",
        "        self.log(\"test_accuracy\", self.accuracy)\n",
        "        self.log(\"test_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXieKV-w3QCQ"
      },
      "source": [
        "The Imagenette dataset is a smaller subset of 10 easily classified classes from Imagenet. It is available to download from `torchvision`, as shown in the cell below. There are 3 different sizes of the images available. Feel free to use whichever version you prefer. It might make a difference in the performance of your model.\n",
        "\n",
        "**Note: After downloading the Imagenette dataset, you will need to set `download=False` in the cell below to avoid errors.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QNN_j8t3QCQ",
        "outputId": "107e6e6d-7a34-40e8-fdb2-1f7e47c05444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to data/imagenette/train/imagenette2-160.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99003388/99003388 [00:11<00:00, 8609935.61it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/imagenette/train/imagenette2-160.tgz to data/imagenette/train/\n",
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz to data/imagenette/test/imagenette2-160.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 99003388/99003388 [00:04<00:00, 20353361.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/imagenette/test/imagenette2-160.tgz to data/imagenette/test/\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import Imagenette\n",
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# Prepare the dataset\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    transforms.Grayscale()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(160),\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    transforms.Grayscale()\n",
        "])\n",
        "\n",
        "train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=False, transform=train_transforms)\n",
        "\n",
        "# Use 10% of the training set for validation\n",
        "train_set_size = int(len(train_dataset) * 0.9)\n",
        "val_set_size = len(train_dataset) - train_set_size\n",
        "\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_set_size, val_set_size], generator=seed)\n",
        "val_dataset.dataset.transform = test_transforms\n",
        "\n",
        "# Use DataLoader to load the dataset\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
        "\n",
        "# Configure the test dataset\n",
        "test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=False, transform=test_transforms)\n",
        "\n",
        "model = BaselineModel()\n",
        "\n",
        "# Add EarlyStopping\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\",\n",
        "                                    mode=\"min\",\n",
        "                                    patience=5)\n",
        "\n",
        "# Configure Checkpoints\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JinwQAQL3QCR",
        "outputId": "abfbcfff-baf7-4206-c798-2a9a0c6f1b82",
        "colab": {
          "referenced_widgets": [
            "77efda4c66d340c5af54b8957d8cb12d",
            "a3240dc96427474598dc85be9e0a18a0",
            "6339620d653a4a4eb8227fecc351707c",
            "0ae5de5d8cc44de8a46257f2c5c00f86"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "Missing logger folder: c:\\Users\\baile\\Documents\\GitHub\\cse6363-assignment3\\lightning_logs\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | estimator | Sequential         | 4.8 M  | train\n",
            "1 | accuracy  | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "4.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.8 M     Total params\n",
            "19.148    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77efda4c66d340c5af54b8957d8cb12d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3240dc96427474598dc85be9e0a18a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6339620d653a4a4eb8227fecc351707c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ae5de5d8cc44de8a46257f2c5c00f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001717879F4C0>\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"c:\\Users\\baile\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1437, in _shutdown_workers\n",
            "    if self._persistent_workers or self._workers_status[worker_id]:\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback], accelerator=\"gpu\", devices=\"auto\")\n",
        "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGEFGZry3QCR"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, num_workers=8, shuffle=False)\n",
        "trainer.test(model=model, dataloaders=test_loader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}